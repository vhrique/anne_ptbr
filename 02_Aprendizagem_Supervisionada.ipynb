{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/bK8PlElekZUo+mNkpiNh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vhrique/anne2024/blob/main/02_Aprendizagem_Supervisionada.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pacotes Utilizados nesta Aula"
      ],
      "metadata": {
        "id": "Cd3zeiof939j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEATqw6E9wuI"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Paradigmas de Aprendizagem\n",
        "\n",
        "Os paradigmas de aprendizagem em redes neurais artificiais (RNAs) s√£o baseados em diferentes maneiras de treinar um modelo e interagir com os dados.\n",
        "De forma geral, existem tr√™s paradigmas principais: aprendizagem supervisionada, aprendizagem n√£o supervisionada e aprendizagem por refor√ßo.\n",
        "Cada um desses paradigmas possui m√©todos distintos de treinar modelos, com base na disponibilidade e tipo de dados, bem como no objetivo final da tarefa.\n",
        "\n",
        "Na aprendizagem supervisionada, o modelo aprende a partir de dados rotulados, tentando prever uma sa√≠da correta com base em entradas espec√≠ficas.\n",
        "\n",
        "<center><img src=\"https://github.com/vhrique/anne2024/blob/main/figures/supervised.jpg?raw=true\" width=\"500\"></center>\n",
        "\n",
        "J√° na aprendizagem n√£o supervisionada, os dados n√£o possuem r√≥tulos, e o modelo busca identificar padr√µes ou estruturas nos dados, como clusters ou associa√ß√µes.\n",
        "\n",
        "<center><img src=\"https://github.com/vhrique/anne2024/blob/main/figures/clustering.jpg?raw=true\" width=\"500\"></center>\n",
        "\n",
        "Por fim, na aprendizagem por refor√ßo, o modelo aprende atrav√©s da intera√ß√£o com um ambiente, recebendo recompensas ou penalidades com base nas a√ß√µes tomadas, ajustando seu comportamento para maximizar a recompensa ao longo do tempo.\n",
        "\n",
        "<center><img src=\"https://github.com/vhrique/anne2024/blob/main/figures/reinforcement.jpg?raw=true\" width=\"300\"></center>"
      ],
      "metadata": {
        "id": "OWbVFRonHWQ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aprendizagem Supervisionada\n",
        "\n",
        "Entre os paradigmas de aprendizagem mais relevantes est√° a aprendizagem supervisionada, que ser√° o foco desta aula.\n",
        "\n",
        "Na aprendizagem supervisionada, o modelo √© treinado utilizando um conjunto de dados rotulados, ou seja, para cada entrada, h√° uma sa√≠da esperada conhecida.\n",
        "O objetivo do modelo √© aprender uma fun√ß√£o que mapeia as entradas para as sa√≠das corretas, generalizando esse conhecimento para prever novas amostras.\n",
        "Esse paradigma √© amplamente aplicado em tarefas de classifica√ß√£o e regress√£o."
      ],
      "metadata": {
        "id": "KFn3siWi-AZC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problemas de Classifica√ß√£o\n",
        "\n",
        "Na classifica√ß√£o, o modelo aprende a categorizar entradas em uma ou mais classes.\n",
        "Um exemplo cl√°ssico √© a classifica√ß√£o de imagens de d√≠gitos escritos √† m√£o, onde o modelo deve identificar corretamente o d√≠gito (0 a 9) de uma imagem.\n",
        "O modelo aprende a identificar padr√µes que distinguem uma classe de outra.\n",
        "\n",
        "As tr√™s principais categorias de classifica√ß√£o s√£o classifica√ß√£o bin√°ria, classifica√ß√£o multiclasse e classifica√ß√£o multilabel. Cada uma tem suas pr√≥prias caracter√≠sticas e desafios."
      ],
      "metadata": {
        "id": "1nd2T5Uh-Ixk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classifica√ß√£o Bin√°ria\n",
        "\n",
        "Na classifica√ß√£o bin√°ria, o modelo tem que decidir entre duas classes poss√≠veis.\n",
        "Por exemplo, um modelo pode classificar e-mails como \"spam\" ou \"n√£o spam\". As sa√≠das s√£o representadas por um √∫nico valor, geralmente 0 ou 1, onde 0 pode significar \"classe negativa\" e 1 \"classe positiva\".\n",
        "A fun√ß√£o de ativa√ß√£o mais comum usada para esse tipo de problema √© a sigmoide, que gera uma probabilidade entre 0 e 1.\n",
        "A fun√ß√£o de perda mais utilizada √© a Binary Cross-Entropy (BCE)."
      ],
      "metadata": {
        "id": "2XE85yZNKFVj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SrP9xb8baCBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classifica√ß√£o Multiclasse\n",
        "\n",
        "Na classifica√ß√£o multiclasse, o modelo precisa classificar as entradas em mais de duas classes mutuamente exclusivas.\n",
        "Um exemplo cl√°ssico √© a classifica√ß√£o de imagens de d√≠gitos escritos √† m√£o, onde cada d√≠gito (0 a 9) √© uma classe diferente.\n",
        "Nesse caso, o modelo produz uma √∫nica sa√≠da que corresponde a uma das classes.\n",
        "A fun√ß√£o de ativa√ß√£o comumente usada para multiclasse √© a softmax, que normaliza as sa√≠das para que elas somem 1, permitindo a interpreta√ß√£o dessas sa√≠das como probabilidades.\n",
        "A fun√ß√£o de perda mais comum √© a Cross-Entropy (entropia cruzada)."
      ],
      "metadata": {
        "id": "DZpb0eelKHbO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vMU8P59VaCb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classifica√ß√£o Multilabel\n",
        "\n",
        "Na classifica√ß√£o multilabel, cada entrada pode pertencer simultaneamente a v√°rias classes, ou seja, as classes n√£o s√£o mutuamente exclusivas.\n",
        "Por exemplo, um sistema de recomenda√ß√£o de filmes pode classificar um filme tanto como \"com√©dia\" quanto \"drama\", ou uma imagem pode conter v√°rios objetos diferentes, como \"gato\", \"carro\" e \"√°rvore\".\n",
        "Nesse caso, o modelo produz v√°rias sa√≠das, uma para cada poss√≠vel classe, e cada sa√≠da √© tratada como um problema de classifica√ß√£o bin√°ria (ou seja, uma classe pode estar presente ou n√£o).\n",
        "Aqui, a sigmoide √© usada em cada sa√≠da, com a fun√ß√£o de perda Binary Cross-Entropy aplicada individualmente para cada classe."
      ],
      "metadata": {
        "id": "s9873peAKJ6m"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wWfzv8zdaC15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problemas de Regress√£o\n",
        "\n",
        "Na regress√£o, o objetivo √© prever um valor cont√≠nuo.\n",
        "Por exemplo, em problemas de previs√£o de temperatura, o modelo aprende a mapear uma s√©rie de vari√°veis (como press√£o e umidade) para prever a temperatura futura.\n",
        "Ao contr√°rio da classifica√ß√£o, onde as sa√≠das s√£o discretas, a regress√£o lida com vari√°veis cont√≠nuas."
      ],
      "metadata": {
        "id": "woHzcEYR-QxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GOqustV3aDlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Algoritmos de Otimiza√ß√£o\n",
        "\n",
        "Os algoritmos de otimiza√ß√£o s√£o fundamentais para o processo de aprendizagem de redes neurais, pois determinam como os pesos dos neur√¥nios s√£o ajustados para minimizar a fun√ß√£o de perda durante o treinamento.\n",
        "O objetivo da otimiza√ß√£o √© encontrar os melhores par√¢metros (pesos e vieses) que permitam √† rede fazer previs√µes precisas em novos dados.\n",
        "\n",
        "A fun√ß√£o de perda mede o qu√£o longe as previs√µes do modelo est√£o dos valores reais, e o papel do algoritmo de otimiza√ß√£o √© minimizar essa fun√ß√£o ajustando gradualmente os pesos.\n",
        "Isso √© feito por meio do c√°lculo do gradiente, que indica a dire√ß√£o e a magnitude da mudan√ßa necess√°ria nos pesos.\n",
        "\n",
        "Agora, vamos explorar alguns dos principais algoritmos de otimiza√ß√£o e suas evolu√ß√µes:"
      ],
      "metadata": {
        "id": "LaQKV-YU-SqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradiente Descendente\n",
        "\n",
        "O gradiente descendente √© o algoritmo de otimiza√ß√£o mais simples e amplamente utilizado.\n",
        "Ele funciona ajustando os pesos na dire√ß√£o oposta ao gradiente da fun√ß√£o de perda com rela√ß√£o a esses pesos.\n",
        "A ideia √© que, ao seguir essa dire√ß√£o de forma iterativa, o algoritmo chegue ao m√≠nimo da fun√ß√£o de perda, onde o modelo realiza as previs√µes mais precisas.\n",
        "\n",
        "Existem tr√™s varia√ß√µes principais do gradiente descendente:\n",
        "\n",
        "- Batch Gradient Descent: Calcula o gradiente em todo o conjunto de dados de treinamento antes de atualizar os pesos. Esse m√©todo pode ser lento e ineficiente para grandes conjuntos de dados.\n",
        "- Stochastic Gradient Descent (SGD): Atualiza os pesos para cada exemplo de treino individual, tornando o processo mais r√°pido, mas introduzindo maior varia√ß√£o nas atualiza√ß√µes.\n",
        "- Mini-Batch Gradient Descent: Combina os dois anteriores, calculando o gradiente em pequenos lotes de dados, acelerando o treinamento e suavizando a varia√ß√£o das atualiza√ß√µes."
      ],
      "metadata": {
        "id": "pFU_GM8cHu32"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2DBgT7DMaFq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Momentum\n",
        "\n",
        "O Momentum foi introduzido como uma melhoria ao gradiente descendente.\n",
        "Ele acelera o processo de converg√™ncia em dire√ß√£o ao m√≠nimo, acumulando uma fra√ß√£o do gradiente anterior em cada atualiza√ß√£o.\n",
        "Isso ajuda a suavizar o caminho em dire√ß√£o ao m√≠nimo, evitando oscila√ß√µes, especialmente em dire√ß√µes que t√™m gradientes mais ruidosos.\n",
        "\n",
        "A ideia √© que, em vez de seguir estritamente a dire√ß√£o do gradiente atual, o modelo leva em conta o \"momento\" da dire√ß√£o em que est√° se movendo, como uma bola rolando por uma superf√≠cie irregular.\n",
        "Isso permite que o modelo alcance o m√≠nimo mais rapidamente."
      ],
      "metadata": {
        "id": "UxUeC9FcICIS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "96Mc02LQaF_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RMSProp\n",
        "\n",
        "O RMSProp √© um m√©todo de otimiza√ß√£o adaptativo que ajusta a taxa de aprendizado individualmente para cada par√¢metro, com base na magnitude dos gradientes recentes.\n",
        "Ele mant√©m uma m√©dia m√≥vel quadrada dos gradientes ao longo do tempo e, ao dividir o gradiente atual por essa m√©dia, corrige a taxa de aprendizado para cada par√¢metro.\n",
        "Isso faz com que RMSProp se adapte melhor a problemas com gradientes que variam em escalas diferentes.\n",
        "\n",
        "Essa adapta√ß√£o da taxa de aprendizado para cada peso torna o treinamento mais est√°vel e eficaz, especialmente em problemas como redes neurais profundas, onde as atualiza√ß√µes dos pesos podem variar muito."
      ],
      "metadata": {
        "id": "z-1SJV1GIDqA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iq3A3H5kaGZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ADAM\n",
        "\n",
        "O ADAM combina o melhor de dois mundos: as ideias do Momentum e do RMSProp.\n",
        "Ele calcula uma m√©dia m√≥vel dos gradientes (como o Momentum) e uma m√©dia m√≥vel dos quadrados dos gradientes (como o RMSProp), ajustando a taxa de aprendizado de forma adaptativa para cada par√¢metro.\n",
        "\n",
        "ADAM tamb√©m inclui uma corre√ß√£o para vi√©s nos primeiros passos, garantindo que as m√©dias m√≥veis comecem corretamente ajustadas.\n",
        "Esse algoritmo √© um dos mais populares atualmente, pois oferece uma converg√™ncia mais r√°pida e est√°vel em diversos tipos de problemas de redes neurais, sendo menos sens√≠vel √† escolha da taxa de aprendizado inicial."
      ],
      "metadata": {
        "id": "qSTI7LBNJf6X"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ji-mSJDDaGyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Outros Algoritmos\n",
        "\n",
        "Al√©m dos algoritmos cl√°ssicos que discutimos (Gradiente Descendente, Momentum, RMSProp e ADAM), existem outros algoritmos de otimiza√ß√£o relevantes que, dependendo do problema e das caracter√≠sticas da rede neural, podem oferecer vantagens em termos de desempenho ou converg√™ncia.\n",
        "\n",
        "O AdaGrad √© um dos primeiros algoritmos de otimiza√ß√£o adaptativos, introduzido antes do RMSProp.\n",
        "Ele ajusta a taxa de aprendizado para cada par√¢metro de forma individual, com base nas atualiza√ß√µes anteriores.\n",
        "Isso significa que par√¢metros raramente atualizados t√™m uma taxa de aprendizado maior, enquanto aqueles que j√° foram ajustados v√°rias vezes t√™m a taxa de aprendizado reduzida.\n",
        "Embora seja √∫til em problemas esparsos, como no processamento de linguagem natural, onde algumas features s√£o raras, AdaGrad pode sofrer de um decaimento excessivo da taxa de aprendizado, o que leva a converg√™ncia mais lenta em muitos casos.\n",
        "\n",
        "O AdaDelta √© uma varia√ß√£o do AdaGrad, projetada para corrigir o problema de decaimento da taxa de aprendizado.\n",
        "Em vez de acumular todas as atualiza√ß√µes anteriores, como o AdaGrad, o AdaDelta mant√©m uma janela deslizante de atualiza√ß√µes recentes, limitando o impacto de atualiza√ß√µes passadas muito distantes.\n",
        "Isso mant√©m a adaptabilidade da taxa de aprendizado sem que ela diminua drasticamente ao longo do tempo.\n",
        "Assim como o RMSProp, AdaDelta √© muito utilizado em redes profundas e outros problemas complexos.\n",
        "\n",
        "O Nadam √© uma combina√ß√£o de ADAM com o conceito de Nesterov Momentum.\n",
        "A diferen√ßa em rela√ß√£o ao Momentum cl√°ssico √© que, no Nesterov Momentum, o c√°lculo do gradiente √© realizado com uma \"vis√£o antecipada\" da dire√ß√£o para onde os pesos est√£o se movendo, o que pode acelerar o processo de converg√™ncia.\n",
        "O Nadam aplica essa ideia no contexto do ADAM, resultando em um algoritmo que pode ser ligeiramente mais eficiente e est√°vel do que o ADAM em certos cen√°rios.\n",
        "\n",
        "O AMSGrad √© uma modifica√ß√£o do ADAM que tenta resolver um problema de converg√™ncia observada no ADAM original, especialmente em situa√ß√µes onde a fun√ß√£o de perda n√£o √© convexa.\n",
        "No ADAM, os par√¢metros de aprendizado podem n√£o convergir para o √≥timo global em algumas situa√ß√µes.\n",
        "O AMSGrad corrige isso, garantindo que as m√©dias m√≥veis dos gradientes s√≥ decaiam, o que melhora a converg√™ncia em alguns problemas."
      ],
      "metadata": {
        "id": "TqWpKy9EPVb7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uB6GULmZHnrp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fun√ß√µes de Perda\n",
        "\n",
        "As fun√ß√µes de perda (ou fun√ß√µes de custo) s√£o componentes centrais no treinamento de redes neurais, pois medem o qu√£o bem o modelo est√° performando.\n",
        "Elas comparam as predi√ß√µes feitas pela rede com os valores reais e retornam um valor num√©rico que indica o erro da previs√£o.\n",
        "O objetivo do treinamento √© minimizar essa fun√ß√£o de perda ajustando os pesos da rede, com a ajuda de algoritmos de otimiza√ß√£o, para que o erro se torne o menor poss√≠vel.\n",
        "\n",
        "Essencialmente, a fun√ß√£o de perda informa √† rede neural como melhorar suas predi√ß√µes ao longo do processo de aprendizado.\n",
        "Dependendo do tipo de problema (classifica√ß√£o, regress√£o, multiclasse, etc.), diferentes fun√ß√µes de perda s√£o utilizadas."
      ],
      "metadata": {
        "id": "oouf0OSw-XdU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Binary Cross-Entropy\n",
        "\n",
        "A Binary Cross-Entropy (BCE) √© comumente usada em problemas de classifica√ß√£o bin√°ria, onde o objetivo √© prever se uma amostra pertence a uma de duas classes.\n",
        "Essa fun√ß√£o mede a diferen√ßa entre a probabilidade prevista e o valor real, penalizando fortemente predi√ß√µes erradas. A f√≥rmula √©:\n",
        "\n",
        "$$\n",
        "\\text{BCE} = - \\frac{1}{N}\\sum_{i=1}^{N}\\left[y_i.log(\\hat{y}_i) + (1 - y_i).log(1-\\hat{y}_i)\\right]\n",
        "$$\n",
        "\n",
        "Aqui, $y_i$ √© o valor real (0 ou 1) e $\\hat{y}_i$ √© a probabilidade prevista.\n",
        "O objetivo √© minimizar essa diferen√ßa, fazendo com que a probabilidade prevista se aproxime do valor real.\n",
        "\n",
        "- Vantagem: Funciona muito bem com problemas bin√°rios, lidando com probabilidades.\n",
        "- Desvantagem: Pode ser mais sens√≠vel a problemas de balan√ßo de classes."
      ],
      "metadata": {
        "id": "l6nKr-_dzLre"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "#### Multilabel Binary Cross-Entropy\n",
        "\n",
        "Em problemas de classifica√ß√£o multilabel, onde uma entrada pode pertencer a mais de uma classe, a Multilabel Binary Cross-Entropy √© utilizada.\n",
        "√â basicamente a BCE aplicada a cada r√≥tulo individualmente.\n",
        "A f√≥rmula √© semelhante √† da BCE, mas ajustada para v√°rias sa√≠das simult√¢neas.\n",
        "\n",
        "- Vantagem: Adequada para problemas onde uma entrada pertence a m√∫ltiplas classes.\n",
        "- Desvantagem: Pode se tornar ineficiente com um grande n√∫mero de classes."
      ],
      "metadata": {
        "id": "D9syOiFgJosh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Categorical Cross-Entropy\n",
        "\n",
        "A Entropia Cruzada Categ√≥rica √© usada em problemas de classifica√ß√£o multiclasse, onde o objetivo √© prever uma entre v√°rias classes mutuamente exclusivas.\n",
        "A f√≥rmula √©:\n",
        "\n",
        "$$\n",
        "\\text{CCE} = - \\frac{1}{N}\\sum_{i=1}^{N}\\sum_{j=1}^{C}y_{ij}.log(\\hat{y}_{ij})\n",
        "$$\n",
        "\n",
        "Aqui, $C$ √© o n√∫mero de classes, $y_{ij}$ √© o valor real (geralmente um vetor one-hot) e $\\hat{y}_{ij}$ √© a probabilidade prevista para a classe $j$.\n",
        "A _softmax_ √© usada como fun√ß√£o de ativa√ß√£o na sa√≠da, convertendo as predi√ß√µes em probabilidades.\n",
        "\n",
        "- Vantagem: Adequada para problemas com v√°rias classes exclusivas.\n",
        "- Desvantagem: N√£o lida bem com situa√ß√µes em que uma inst√¢ncia pode pertencer a m√∫ltiplas classes."
      ],
      "metadata": {
        "id": "sz7NEBfzTAkA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cross-Entropy como Fun√ß√£o de Perda em Redes Neurais\n",
        "\n",
        "A entropia cruzada (cross-entropy) tem suas origens na teoria da informa√ß√£o, desenvolvida por Claude Shannon na d√©cada de 1940.\n",
        "A ideia central da teoria da informa√ß√£o √© quantificar a quantidade de informa√ß√£o ou incerteza presente em um conjunto de dados, e a entropia √© uma medida dessa incerteza.\n",
        "A entropia de Shannon mede o grau de imprevisibilidade de um sistema de eventos, sendo usada para descrever a incerteza associada a uma distribui√ß√£o de probabilidades.\n",
        "\n",
        "No contexto de redes neurais, a entropia cruzada √© uma medida da diverg√™ncia entre duas distribui√ß√µes de probabilidade: a distribui√ß√£o verdadeira dos r√≥tulos (a sa√≠da correta) e a distribui√ß√£o prevista pelo modelo.\n",
        "A f√≥rmula original da entropia cruzada √© baseada na diverg√™ncia de Kullback-Leibler (KL Divergence), que mede a diferen√ßa entre duas distribui√ß√µes de probabilidade $P$ e $Q$.\n",
        "No caso de uma rede neural, $P$ √© a distribui√ß√£o verdadeira dos r√≥tulos (normalmente representada por um vetor one-hot) e $Q$ √© a distribui√ß√£o de probabilidade prevista pelo modelo.\n",
        "\n",
        "A f√≥rmula da entropia cruzada √© dada por:\n",
        "\n",
        "$$\n",
        "H(P,Q) = - \\sum_{i=1}^{C}P(i)log(Q(i))\n",
        "$$\n",
        "\n",
        "Onde:\n",
        "\n",
        "- $P(i)$ √© a probabilidade verdadeira para a classe $i$ (em problemas de classifica√ß√£o, geralmente 0 ou 1).\n",
        "- $Q(i)$ √© a probabilidade prevista pelo modelo para a classe $i$.\n",
        "\n",
        "A entropia cruzada mede o qu√£o bem o modelo est√° capturando a distribui√ß√£o verdadeira dos r√≥tulos.\n",
        "Quando $P(i)$ √© 1 (ou seja, a classe $ùëñ$ √© a correta), a entropia cruzada penaliza o modelo se a probabilidade $ùëÑ(i)$ n√£o estiver pr√≥xima de 1."
      ],
      "metadata": {
        "id": "rjPy1L8UVhtJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Margin (Hinge)\n",
        "\n",
        "O Hinge Loss √© usado com m√°quinas de vetores de suporte (SVMs), mas tamb√©m pode ser aplicado em redes neurais para problemas de classifica√ß√£o bin√°ria.\n",
        "Ele for√ßa o modelo a maximizar a margem entre as classes, penalizando erros de classifica√ß√£o de forma mais agressiva.\n",
        "\n",
        "A f√≥rmula para um problema bin√°rio √©:\n",
        "\n",
        "$$\n",
        "L = \\sum_{i=1}^{N}\\text{max}(0,1-y_i.\\hat{y}_i)\n",
        "$$\n",
        "\n",
        "Aqui, $y_i$ s√£o os r√≥tulos reais (+1 ou -1), $\\hat{y}_{i}$ e s√£o as predi√ß√µes do modelo.\n",
        "\n",
        "- Vantagem: Eficaz em maximizar a separa√ß√£o entre as classes.\n",
        "- Desvantagem: Principalmente usado em SVMs e menos comum em redes neurais."
      ],
      "metadata": {
        "id": "UNjXoqpPJz0V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mean Squared Error\n",
        "\n",
        "O MSE √© amplamente usado em problemas de regress√£o, onde o objetivo √© prever valores cont√≠nuos.\n",
        "Ele mede a diferen√ßa m√©dia entre as predi√ß√µes do modelo e os valores reais, elevando ao quadrado essas diferen√ßas para garantir que erros positivos e negativos n√£o se cancelem.\n",
        "A f√≥rmula √©:\n",
        "\n",
        "$$\n",
        "\\text{MSE} = \\frac{1}{N}\\sum_{i=1}^N(y_i - \\hat{y}_i)^2\n",
        "$$\n",
        "\n",
        "onde $y_i$ √© o valor real e $\\hat{y}_i$ √© a predi√ß√£o do modelo.\n",
        "O quadrado das diferen√ßas garante que erros grandes tenham um impacto maior no valor final.\n",
        "\n",
        "- Vantagem: Simples de calcular e amplifica grandes erros.\n",
        "- Desvantagem: Sens√≠vel a outliers, j√° que erros grandes t√™m um impacto desproporcional."
      ],
      "metadata": {
        "id": "cVV4DE8uJwwx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mean Absolute Error\n",
        "\n",
        "O MAE √© outra fun√ß√£o de perda usada para problemas de regress√£o, mas, ao contr√°rio do MSE, mede a diferen√ßa absoluta m√©dia entre os valores previstos e os valores reais.\n",
        "Sua f√≥rmula √©:\n",
        "\n",
        "$$\n",
        "\\text{MSE} = \\frac{1}{N}\\sum_{i=1}^N \\left|y_i - \\hat{y}_i \\right|\n",
        "$$\n",
        "\n",
        "- Vantagem: Mais robusto a outliers do que o MSE.\n",
        "- Desvantagem: N√£o diferencia grandes e pequenos erros da mesma forma que o MSE."
      ],
      "metadata": {
        "id": "3rY99ezyRNXR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Huber Loss\n",
        "\n",
        "A Huber Loss √© uma fun√ß√£o de perda que combina as vantagens do Erro Quadr√°tico M√©dio (MSE) e do Erro Absoluto M√©dio (MAE), oferecendo uma abordagem robusta para problemas de regress√£o, especialmente na presen√ßa de outliers.\n",
        "Ela foi projetada para tratar grandes erros de forma mais eficiente do que o MSE, que √© altamente sens√≠vel a outliers, enquanto mant√©m a simplicidade do MAE em regi√µes de pequenos erros.\n",
        "A f√≥rmula da Huber Loss √© definida de forma diferente para erros pequenos e grandes:\n",
        "\n",
        "$$\n",
        "L_{\\delta}(y_i, \\hat{y}_i) =\n",
        "\\begin{cases}\n",
        "\\frac{1}{2}(y_i - \\hat{y}_i)^2 & \\text{se } |y_i - \\hat{y}_i| \\leq \\delta \\\\\n",
        "\\delta \\cdot (|y_i - \\hat{y}_i| - \\frac{1}{2} \\delta) & \\text{se } |y_i - \\hat{y}_i| > \\delta\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "onde $y_i$ √© o valor real, $\\hat{y}_i$ √© a previs√£o do modelo e $\\delta$ √© um par√¢metro que define o limite entre erros pequenos e grandes.\n",
        "\n",
        "A Huber Loss funciona de forma suave em rela√ß√£o a pequenos erros, como o MSE, mas trata erros grandes de maneira mais robusta, como o MAE.\n",
        "Isso faz com que seja uma fun√ß√£o intermedi√°ria que lida bem tanto com ru√≠dos pequenos quanto com outliers, sendo especialmente √∫til em problemas de regress√£o.\n",
        "\n",
        "Vantagens:\n",
        "\n",
        "- Robustez a outliers: Quando h√° grandes erros ou outliers, a Huber Loss n√£o amplifica esses erros tanto quanto o MSE, evitando que um pequeno n√∫mero de outliers distor√ßa significativamente o modelo.\n",
        "- Suavidade em pequenos erros: Para erros pequenos, a Huber Loss se comporta como o MSE, permitindo que a fun√ß√£o de perda seja diferenci√°vel e suave, o que facilita a otimiza√ß√£o.\n",
        "\n",
        "Desvantagens:\n",
        "\n",
        "- Escolha de $\\delta$: O valor de\n",
        "$\\delta$ deve ser escolhido cuidadosamente, pois um valor mal ajustado pode levar a um comportamento inadequado da fun√ß√£o de perda. Sefor muito pequeno, o modelo se comportar√° quase como o MAE, e se for muito grande, se aproximar√° do MSE, perdendo as vantagens da robustez\n",
        "\n",
        "A Huber Loss √© amplamente utilizada em problemas de regress√£o onde h√° a presen√ßa de outliers nos dados, pois oferece um equil√≠brio entre ser suave para erros pequenos e robusta para grandes erros. Al√©m disso, √© preferida em aplica√ß√µes de machine learning onde o MSE tende a ser excessivamente influenciado por grandes outliers."
      ],
      "metadata": {
        "id": "Spe-X0XiKSOW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Outras Fun√ß√µes de Perda\n",
        "\n",
        "A KL Divergence √© utilizada para medir a diferen√ßa entre duas distribui√ß√µes de probabilidade, sendo particularmente √∫til em modelos probabil√≠sticos, como variational autoencoders (VAEs).\n",
        "Ela n√£o √© propriamente uma fun√ß√£o de perda no sentido tradicional, mas √© amplamente usada para regularizar a distribui√ß√£o de sa√≠da de um modelo para que seja similar a uma distribui√ß√£o-alvo.\n",
        "\n",
        "A Cosine Similarity Loss mede o √¢ngulo entre dois vetores, sendo usada para comparar a similaridade entre vetores em vez de medir a diferen√ßa absoluta.\n",
        "Isso √© especialmente √∫til em problemas de aprendizado de representa√ß√µes, como em redes neurais siamesas e embedding learning.\n",
        "\n",
        "A Focal Loss foi introduzida para tratar o problema de desbalanceamento de classes, em que algumas classes s√£o muito mais representadas que outras.\n",
        "Ela √© uma modifica√ß√£o da entropia cruzada que coloca mais peso nas amostras dif√≠ceis (ou seja, aquelas que s√£o classificadas de forma incorreta).\n",
        "\n",
        "Tamb√©m chamada de Huber Loss, mas com uma implementa√ß√£o ligeiramente diferente, a Smooth L1 Loss √© amplamente utilizada em redes neurais para detec√ß√£o de objetos. Ela √© mais robusta a outliers do que a MSE e mais est√°vel do que o MAE.\n",
        "\n",
        "A Dice Loss √© uma fun√ß√£o de perda comumente usada em problemas de segmenta√ß√£o de imagens, especialmente em √°reas m√©dicas, onde √© necess√°rio calcular a sobreposi√ß√£o entre a √°rea predita e a √°rea verdadeira.\n",
        "√â derivada do coeficiente de Dice, que mede a similaridade entre dois conjuntos.\n",
        "\n",
        "A Triplet Loss √© usada para aprendizado de embeddings e aprendizado m√©trico, particularmente em redes siamesas.\n",
        "A fun√ß√£o de perda incentiva a rede a reduzir a dist√¢ncia entre embeddings de amostras semelhantes (o ancor e o positivo) e aumentar a dist√¢ncia entre o ancor e amostras dissimilares (o negativo).\n",
        "\n",
        "A Wing Loss √© uma fun√ß√£o de perda desenhada especificamente para problemas de detec√ß√£o de landmarks faciais, onde pequenos erros precisam ser suavemente penalizados, mas grandes erros devem ser penalizados de forma mais forte."
      ],
      "metadata": {
        "id": "ZwbBuiBwYw1O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aprendizagem = Representa√ß√£o + Otimiza√ß√£o + Avalia√ß√£o\n",
        "\n",
        "Conforme indicado por Pedro Domingos (2012), tr√™s componentes aparecem em todos os paradigmas de aprendizagem: representa√ß√£o, otimiza√ß√£o e avalia√ß√£o.\n",
        "Esses tr√™s componentes s√£o fundamentais para qualquer paradigma de aprendizagem, desde as tarefas supervisionadas mais simples at√© as mais complexas formas de aprendizado, como o _self-supervised learning_.\n",
        "A intera√ß√£o entre esses componentes define o sucesso e a efic√°cia de um modelo ao generalizar para novos dados e resolver problemas reais.\n",
        "\n",
        "<center><img src=\"https://raw.githubusercontent.com/vhrique/anne2024/8eb24ed5fc4d5ffd55d1664b512417ad8a2d71a0/figures/mapa_mental_supervised_learning_reduced.drawio.svg\" width=\"600\"></center>\n",
        "\n",
        "## Representa√ß√£o\n",
        "\n",
        "A representa√ß√£o refere-se a como os dados e o conhecimento s√£o modelados internamente pelo modelo. Ela define como as caracter√≠sticas dos dados ser√£o manipuladas para que o modelo possa aprender padr√µes √∫teis, e sua escolha tem um impacto significativo no desempenho de um modelo.\n",
        "\n",
        "## Otimiza√ß√£o\n",
        "\n",
        "O processo de otimiza√ß√£o envolve a maneira como o modelo ajusta seus par√¢metros internos para minimizar uma fun√ß√£o de perda, que mede o qu√£o longe as previs√µes est√£o das sa√≠das desejadas. Em redes neurais, esse processo √© realizado por algoritmos como o gradiente descendente, que ajusta os pesos das conex√µes neurais para minimizar a diferen√ßa entre a predi√ß√£o do modelo e o r√≥tulo correto, atrav√©s de t√©cnicas como o backpropagation. Em suma, a otimiza√ß√£o busca garantir que o modelo aprenda da melhor maneira poss√≠vel com os dados dispon√≠veis, ajustando-se para capturar os padr√µes mais relevantes e reduzir o erro nas predi√ß√µes.\n",
        "\n",
        "## Avalia√ß√£o\n",
        "\n",
        "Por fim, a avalia√ß√£o mede o qu√£o bem o modelo aprendeu a tarefa. As m√©tricas de avalia√ß√£o variam conforme a tarefa e o tipo de aprendizado. Na aprendizagem supervisionada, por exemplo, para classifica√ß√£o, utilizamos m√©tricas como acur√°cia ou F1-score, enquanto, em regress√£o, utilizamos erro quadr√°tico m√©dio (MSE) ou erro absoluto m√©dio (MAE). Ao treinar redes neurais artificiais, utilizamos fun√ß√µes de perda para guiar o processo de aprendizagem por meio de otimiza√ß√£o. Otimiza√ß√£o e avalia√ß√£o, portanto, s√£o componentes complementares e essenciais para garantir que o modelo de aprendizado de m√°quina aprenda de forma eficiente e seja capaz de realizar boas previs√µes em novos dados.\n",
        "\n",
        "## Considera√ß√µes sobre Representa√ß√£o e Vi√©s Indutivo\n",
        "\n",
        "Diferentes algoritmos de aprendizado de m√°quina utilizam diferentes tipos de representa√ß√£o. Por exemplo, o K-Nearest Neighbors (KNN) representa os dados como pontos em um espa√ßo m√©trico, assumindo que amostras pr√≥ximas t√™m comportamentos similares, o que reflete um vi√©s indutivo de proximidade espacial. J√° em √°rvores de decis√£o, a representa√ß√£o dos dados √© estruturada hierarquicamente, onde divis√µes sucessivas criam n√≥s e folhas que categorizam as amostras, impondo um vi√©s de segmenta√ß√£o bin√°ria nos dados.\n",
        "\n",
        "Nas redes neurais, os dados s√£o representados de forma abstrata atrav√©s de camadas de neur√¥nios, onde cada camada transforma os dados em representa√ß√µes progressivamente mais complexas e abstratas, refletindo um vi√©s indutivo de que os padr√µes nos dados podem ser aprendidos atrav√©s de composi√ß√µes hier√°rquicas de fun√ß√µes n√£o-lineares. Em uma rede neural profunda, por exemplo, camadas sucessivas de neur√¥nios aprendem representa√ß√µes progressivamente mais complexas dos dados. No in√≠cio, as camadas podem detectar bordas ou formas simples em uma imagem, enquanto camadas mais profundas podem aprender a identificar objetos ou partes mais complexas."
      ],
      "metadata": {
        "id": "5_xJdaLqHkV1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Refer√™ncias\n",
        "\n",
        "- Domingos, P. (2012). A few useful things to know about machine learning. Communications of the ACM, 55(10), 78-87.\n",
        "- Shannon, C. E. (1948). A mathematical theory of communication. The Bell system technical journal, 27(3), 379-423."
      ],
      "metadata": {
        "id": "yg-Auww0LByt"
      }
    }
  ]
}